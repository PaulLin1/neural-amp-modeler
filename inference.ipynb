{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5666db55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependecies\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import math\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.enabled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8ed5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "def preprocess_audio(path, target_rms=0.1, mu_law=False):\n",
    "    sr, waveform = wavfile.read(path)\n",
    "    if waveform.ndim > 1:\n",
    "        waveform = waveform.mean(axis=1)\n",
    "    waveform = waveform.astype(np.float32)\n",
    "    waveform -= np.mean(waveform)\n",
    "    \n",
    "    # Normalize amplitude and prevent clipping\n",
    "    waveform /= (np.max(np.abs(waveform)) + 1e-7)\n",
    "    waveform *= 0.99\n",
    "    \n",
    "    # High-pass filter to remove DC / subsonic\n",
    "    b, a = butter(1, 20 / (sr / 2), btype='highpass')\n",
    "    waveform = filtfilt(b, a, waveform)\n",
    "    \n",
    "    # RMS normalization\n",
    "    def rms(x): return np.sqrt(np.mean(x**2))\n",
    "    waveform *= target_rms / (rms(waveform) + 1e-9)\n",
    "    \n",
    "    if mu_law:\n",
    "        waveform = mu_law_encode(waveform)\n",
    "    \n",
    "    return sr, waveform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82ef308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "import pickle\n",
    "from scipy.io import wavfile\n",
    "\n",
    "\n",
    "class CausalConv1d(nn.Module):\n",
    "    \"\"\"1D causal convolution.\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, dilation=1):\n",
    "        super().__init__()\n",
    "        self.pad = (kernel_size - 1) * dilation\n",
    "        self.conv = nn.Conv1d(\n",
    "            in_channels, out_channels, kernel_size,\n",
    "            padding=self.pad, dilation=dilation\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        if self.pad > 0:\n",
    "            out = out[:, :, :-self.pad]  # remove causal padding\n",
    "        return out\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"Residual block with gated activation.\"\"\"\n",
    "    def __init__(self, channels, kernel_size, dilation):\n",
    "        super().__init__()\n",
    "        self.filter_conv = CausalConv1d(channels, channels, kernel_size, dilation)\n",
    "        self.gate_conv = CausalConv1d(channels, channels, kernel_size, dilation)\n",
    "        self.residual_conv = nn.Conv1d(channels, channels, 1)\n",
    "        self.skip_conv = nn.Conv1d(channels, channels, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = torch.tanh(self.filter_conv(x)) * torch.sigmoid(self.gate_conv(x))\n",
    "        skip = self.skip_conv(out)\n",
    "        res = self.residual_conv(out) + x\n",
    "        return res, skip\n",
    "\n",
    "class WaveNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, channels=16, kernel_size=3, num_blocks=1, dilations=None):\n",
    "        super().__init__()\n",
    "        self.causal_in = CausalConv1d(in_channels, channels, kernel_size=1)\n",
    "        self.dilations = dilations if dilations is not None else [2 ** i for i in range(10)]\n",
    "        self.blocks = nn.ModuleList([\n",
    "            ResidualBlock(channels, kernel_size, d) \n",
    "            for _ in range(num_blocks) \n",
    "            for d in self.dilations\n",
    "        ])\n",
    "        self.relu = nn.ReLU()\n",
    "        self.out1 = nn.Conv1d(channels, channels, 1)\n",
    "        self.out2 = nn.Conv1d(channels, 1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.causal_in(x)\n",
    "        skip_connections = 0\n",
    "        for block in self.blocks:\n",
    "            x, skip = block(x)\n",
    "            skip_connections = skip_connections + skip if isinstance(skip_connections, torch.Tensor) else skip\n",
    "        out = self.relu(skip_connections)\n",
    "        out = self.relu(self.out1(out))\n",
    "        out = self.out2(out)\n",
    "        return out\n",
    "\n",
    "    @property\n",
    "    def receptive_field(self):\n",
    "        rf = 1\n",
    "        for d in self.dilations:\n",
    "            rf += (3 - 1) * d\n",
    "        return rf\n",
    "\n",
    "class AmpDatasetVectorized(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Fully vectorized dataset:\n",
    "    - Feed entire waveform to model at once\n",
    "    - No Python slicing loops\n",
    "    - Output is trimmed to match receptive field\n",
    "    \"\"\"\n",
    "    def __init__(self, clean_wave, amp_wave, model: WaveNet):\n",
    "        self.x = torch.tensor(clean_wave, dtype=torch.float32).unsqueeze(0)  # (1, L)\n",
    "        self.y = torch.tensor(amp_wave, dtype=torch.float32).unsqueeze(0)    # (1, L)\n",
    "        self.rf = model.receptive_field\n",
    "        assert self.x.shape[-1] >= self.rf, \"Waveform too short for receptive field\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1  # Entire waveform in one pass\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Slice outputs to ignore initial zeros from causal padding\n",
    "        x_input = self.x\n",
    "        y_target = self.y[:, self.rf - 1:]  # trim first rf-1 samples\n",
    "        return x_input, y_target\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = torch.load(\"model.pkl\", weights_only=False, map_location=\"cpu\").to(device)\n",
    "\n",
    "\n",
    "sr, waveform = wavfile.read(\"riff_clean.wav\")\n",
    "if waveform.ndim > 1:\n",
    "    waveform = waveform.mean(axis=1)\n",
    "\n",
    "waveform = waveform.astype(np.float32)\n",
    "waveform /= np.abs(waveform).max()\n",
    "# clean_quant = mu_law_encode(waveform)\n",
    "model.eval()\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     # x: 1D tensor of input waveform\n",
    "#     x = torch.tensor(waveform, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)  # (1, L)\n",
    "    \n",
    "#     # forward pass\n",
    "#     y_pred = model(x)[:, :, model.receptive_field - 1:]  # remove initial causal padding\n",
    "    \n",
    "#     y_pred = y_pred.squeeze(0).cpu()  # (L - rf + 1,)\n",
    "\n",
    "# # q = mu_law_decode(clean_quant)\n",
    "# q = y_pred.squeeze(0).numpy()\n",
    "\n",
    "# from scipy.io.wavfile import write\n",
    "# write(\"outpu11.wav\", sr, (q * 32767).astype(np.int16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77ee938",
   "metadata": {},
   "outputs": [],
   "source": [
    "MU = 2048\n",
    "\n",
    "def mu_law_encode(x, mu=MU):\n",
    "    x = np.clip(x, -1.0, 1.0)\n",
    "    mag = np.log1p(mu * np.abs(x)) / np.log1p(mu)\n",
    "    encoded = ((np.sign(x) * mag) + 1) / 2 * mu\n",
    "    return np.round(encoded).astype(np.int64)\n",
    "def mu_law_decode(encoded, mu=MU):\n",
    "    x = (encoded.astype(np.float32) / mu) * 2 - 1\n",
    "    sign = np.sign(x)\n",
    "    mag = (1 / mu) * ((1 + mu) ** np.abs(x) - 1)\n",
    "    return sign * mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "120f74f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_797074/3873250676.py:6: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  sr, waveform = wavfile.read(path)\n"
     ]
    }
   ],
   "source": [
    "from scipy.io import wavfile\n",
    "\n",
    "sr, clean_quant = preprocess_audio(\"scale_clean.wav\")\n",
    "sr, amp_quant   = preprocess_audio(\"scale_amp.wav\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# q = mu_law_decode(amp_quant)\n",
    "from scipy.io.wavfile import write\n",
    "write(\"outpu11.wav\", sr, (clean_quant * 32767).astype(np.int16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cde3d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming clean_tensor is [seq_len] or [batch_size, seq_len]\n",
    "# tensor_np = pred_np\n",
    "print(q.shape)\n",
    "plt.figure(figsize=(12, 4))\n",
    "# plt.plot(mu_law_decode(y_pred.squeeze(0).numpy()), color='blue')\n",
    "plt.plot(q, color='blue')\n",
    "\n",
    "plt.title(\"Clean Tensor Waveform\")\n",
    "plt.xlabel(\"Sample Index\")\n",
    "plt.ylabel(\"Amplitude (quantized)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
